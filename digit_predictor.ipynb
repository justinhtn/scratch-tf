{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justinhtn/scratch-tf/blob/main/digit_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pFmdEL6e22X"
      },
      "source": [
        "## Our Goal\n",
        "Build a model that can predict the labels of any set of handwritten digits between 0-9 that's thrown its way. 👍\n",
        "\n",
        "### **Recomended reading:**\n",
        "- [Keras Docs](https://keras.io/)\n",
        "- [Sequential model guide](https://keras.io/getting-started/sequential-model-guide/)\n",
        "- [Keras Github](https://github.com/keras-team/keras/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMHhJgs0EpQS"
      },
      "source": [
        "# Sequential is a Keras model in which each layer is stacked on top of each other.\n",
        "from keras.models import Sequential\n",
        "\n",
        "# The following imports will be used for creating individual network layers.\n",
        "# 'Conv2, MaxPooling2D, Flatten and Dropout' will be used to specifically accomodate the\n",
        "# convolutional layers while 'Dense' will allow us to create fully connected layers.\n",
        "# We'll go through these in more detail when we use them later in the notebook.\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Adding early stopping will stop our network when its performance improvement starts to dwindle.\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# We'll be working with the MNIST dataset which consists of 60,000 28x28\n",
        "# images along with a test set of 10,000 images. Both training and test sets include labels.\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Importing extra utils from keras, numPy and scikit learn to plot and transform training and test data\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage.transform import resize\n",
        "\n",
        "# loading saved models back into our notebook\n",
        "from keras.models import load_model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zON4Fb0_tyKN"
      },
      "source": [
        "## Load data\n",
        "We'll set up a load_data function to do the following:\n",
        "- Load training and testing data from the MNIST dataset into a tuple.\n",
        "- Reshape the data into a shape that CNN's require. [Batch size, Width, Height, Number of Channels]\n",
        "- [One Hot Encode](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f) the training and test lables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i22B_XW5unrn"
      },
      "source": [
        "def load_data():\n",
        "# loading dataset\n",
        "  (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        " \n",
        "# reshape and convery type\n",
        "  X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "  X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        " \n",
        "# one hot encoding labels\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test = to_categorical(y_test)\n",
        "  \n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx6ZeQOJ5c42"
      },
      "source": [
        "## Transform data\n",
        "Next, we'll create a prep_data function that will pre-process that loaded data:\n",
        "- Take in the training and test image data that the load_data() function returns.\n",
        "- Convert training and test data to float32 format.\n",
        "- Normalize data to values between 0-1 rather than 0-255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1oiDXHB5gsj"
      },
      "source": [
        "def prep_data(train_imgs, test_imgs):\n",
        "# convert to float\n",
        "  train_imgs_float = train_imgs.astype('float32')\n",
        "  test_imgs_float = test_imgs.astype('float32')\n",
        " \n",
        "# noralize between 0-1\n",
        "  train_imgs_normal = train_imgs_float / 255.0\n",
        "  test_imgs_normal = test_imgs_float / 255.0\n",
        "\n",
        "  return train_imgs_normal, test_imgs_normal"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Yiqx7qyIk2"
      },
      "source": [
        "## Model building\n",
        "The sequential model we will be building will consist of 11 layers because it's fun to experiment. We will utilize the keras layers Conv2D, Flatten, Dense, Dropout and MaxPooling2D.\n",
        "\n",
        "**Resources:**\n",
        "[Keras core layers](https://keras.io/layers/core/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kEl9fD3yAAR"
      },
      "source": [
        "def cnn_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(50, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "  model.add(Conv2D(50, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(50, (3, 3), activation='relu'))\n",
        "  model.add(Conv2D(50, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(150, activation='relu'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compiling and save model\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjNPU51xHE7B"
      },
      "source": [
        "cnn_instance = cnn_model()\n",
        "cnn_instance.summary()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcKZI5zy8Rcc"
      },
      "source": [
        "## Training and Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_268kLY8NIH"
      },
      "source": [
        "def train_and_evaluate():\n",
        "  model = cnn_model()\n",
        "  X_train, y_train, X_test, y_test = load_data()\n",
        "  X_train, X_test = prep_data(X_train, X_test)\n",
        "  early_stopping = EarlyStopping(patience=3)\n",
        "  model.fit(X_train, y_train, epochs=5, batch_size=150, callbacks=[early_stopping])\n",
        "  model.save(\"cnn_v4.h5\")\n",
        "\n",
        "  test_accuracy = model.evaluate(X_test, y_test)\n",
        "  train_accuracy = model.evaluate(X_train, y_train)\n",
        "\n",
        "  print(f\"Test loss: {round(test_accuracy[0]*100,5)}%\")\n",
        "  print(f\"Test accuracy: {round(test_accuracy[1]*100, 5)}%\")\n",
        "  print(f\"Error percentage: {round(100-test_accuracy[1]*100,5)}%\")\n",
        "\n",
        "  print(f\"Train loss: {round(train_accuracy[0]*100, 5)}%\")\n",
        "  print(f\"Train accuracy: {round(train_accuracy[1]*100, 5)}%\")\n",
        "  print(f\"Error percentage: {round(100-train_accuracy[1]*100,5)}%\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQq7VeHCH6Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7cc6db7-20cd-4aaa-a9f1-1a9812d6adc8"
      },
      "source": [
        "train_and_evaluate()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "398/400 [============================>.] - ETA: 0s - loss: 0.2275 - accuracy: 0.9301WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "400/400 [==============================] - 19s 24ms/step - loss: 0.2267 - accuracy: 0.9303\n",
            "Epoch 2/5\n",
            "398/400 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 0.9818WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "400/400 [==============================] - 9s 23ms/step - loss: 0.0576 - accuracy: 0.9818\n",
            "Epoch 3/5\n",
            "399/400 [============================>.] - ETA: 0s - loss: 0.0430 - accuracy: 0.9864WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "400/400 [==============================] - 9s 23ms/step - loss: 0.0429 - accuracy: 0.9865\n",
            "Epoch 4/5\n",
            "399/400 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9896WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "400/400 [==============================] - 9s 24ms/step - loss: 0.0330 - accuracy: 0.9896\n",
            "Epoch 5/5\n",
            "399/400 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9910WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "400/400 [==============================] - 10s 24ms/step - loss: 0.0271 - accuracy: 0.9910\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0193 - accuracy: 0.9935\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0117 - accuracy: 0.9963\n",
            "Test loss: 1.92527%\n",
            "Test accuracy: 99.35%\n",
            "Error percentage: 0.65%\n",
            "Train loss: 1.16798%\n",
            "Train accuracy: 99.62834%\n",
            "Error percentage: 0.37166%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raXWtEglFNaY"
      },
      "source": [
        "##Loading and Predict Single Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF9FYtj7-Zhk"
      },
      "source": [
        "def load_test_image(image_path):\n",
        "# load in the image and convert to grey scale. \n",
        "# ** NOTE ** load_img also normalizes the image file\n",
        "\timg_loaded = load_img(image_path, color_mode=\"grayscale\")\n",
        "# resize image to 28x28\n",
        "\timg_resized = resize(np.array(img_loaded), (28, 28))\n",
        "# reshape to have 1 channel and 1 for the batch size\n",
        "\timg_reshaped = img_resized.reshape((1, 28, 28, 1))\n",
        "# convert to float\n",
        "\timg_normal = img_reshaped.astype('float32')\n",
        "\treturn img_normal"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXl9ZdfYGDw0"
      },
      "source": [
        "def predictImage(image_path, model_path):\n",
        "  loaded_image = load_test_image(image_path)\n",
        "  model = load_model(model_path)\n",
        "  digit = np.argmax(model.predict(loaded_image), axis=-1)\n",
        "  print(digit)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf9nobCHG2s6",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c1257e-43aa-4eb1-d317-7242493df517"
      },
      "source": [
        "predictImage('/content/34367226-1897-4D1C-AF6E-57AB7156B7DE.jpeg', 'cnn_v4.h5')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXJwWS7nPhKM",
        "outputId": "a5b87d5a-aee1-45f5-d68a-211a300aac05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!!git clone https://gist.github.com/8409b3feec20f159d8a50b0a811d3bca.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Cloning into '8409b3feec20f159d8a50b0a811d3bca'...\",\n",
              " 'remote: Enumerating objects: 6, done.\\x1b[K',\n",
              " 'remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 6\\x1b[K',\n",
              " 'Unpacking objects:  16% (1/6)   ',\n",
              " 'Unpacking objects:  33% (2/6)   ',\n",
              " 'Unpacking objects:  50% (3/6)   ',\n",
              " 'Unpacking objects:  66% (4/6)   ',\n",
              " 'Unpacking objects:  83% (5/6)   ',\n",
              " 'Unpacking objects: 100% (6/6)   ',\n",
              " 'Unpacking objects: 100% (6/6), done.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEKcqPhTPhmY"
      },
      "source": [
        "%run /content/8409b3feec20f159d8a50b0a811d3bca/draw.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDgOBL4BPnMF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}